# Discrimination in Machine Learning

A hands-on demonstration of how applying machine learning can lead to discrimination.
Without being cautious in selecting data and applying learning algorithms, resulting models can
lead to decisions that are either hostile to certain groups of people or ignore their needs.

This repo contains example datasets and a guided path through running "real" machine learning code
using [Python](https://www.python.org/) and [scikit-learn](http://scikit-learn.org/) through
visual and interactive [Jupyter notebooks](http://jupyter.org/).

The datasets and code here are only "real" in sense that they're working software, illustrating
issues in machine learning using technologies that are now part of the mainstream IT industry.
However, they are intentionally trivial examples for demonstration purposes and don't reflect
industry-standard techniques or the more subtle issues that arise in actual projects.

## Step 1: Starting out with our automated Résumé reviewer

Here we introduce our machine learning project: an automated resume reviewer to help our
company's HR department filter job applicants. Since competition for talent is fierce,
management wants this rolled out fast. So we grab some historical data and plug it into an
easy-to-use open-source toolkit. Sounds pretty straightforward, right?

Link to notebook: [step-1.ipynb](step-1.ipynb)
